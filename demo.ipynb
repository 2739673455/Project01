{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(path=\"csv\", data_files=\"data/news_categorize.csv\")[\"train\"]\n",
    "dataset = dataset.shuffle().select(range(50000))\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True)\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "# 定义预处理函数\n",
    "def preprocess_func(example):\n",
    "    return tokenizer(\n",
    "        example[\"title\"],\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_special_tokens_mask=True,\n",
    "    )\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_func, batched=True)\n",
    "encoded_dataset.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "# 创建MLM数据整理器，动态生成掩码和填充\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15,  # 掩码比例\n",
    ")\n",
    "# 实例化DataLoader\n",
    "train_batch_size = 32\n",
    "test_batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    encoded_dataset[\"train\"],\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    encoded_dataset[\"test\"],\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "# 查看掩蔽后的数据\n",
    "example_batch = next(iter(train_dataloader))\n",
    "for i in range(5):\n",
    "    masked_tokens = tokenizer.convert_ids_to_tokens(example_batch[\"input_ids\"][i])\n",
    "    print(\"\".join(masked_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# 加载预训练模型\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "# 自定义模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.linear = nn.Linear(768, output_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 关闭bert的梯度计算\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        output = self.linear(output.last_hidden_state)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Model(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, lr, num_epoch, device):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for batch_count, batch in enumerate(train_dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            # 前向传播\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            # 反向传播\n",
    "            loss = criterion(output.view(-1, tokenizer.vocab_size), labels.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #  梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            if batch_count % 10 == 0:\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                # labels != -100 为被掩蔽的位置\n",
    "                mask = labels != -100\n",
    "                accuracy = (preds[mask] == labels[mask]).sum().item() / mask.sum().item()\n",
    "                print(f\"\\repoch:{epoch:0>2}[{'='*(int((batch_count+1) / len(train_dataloader) * 50)):<50}]\", end=\"\")\n",
    "                print(f\" loss:{loss}, accuracy={accuracy}\")\n",
    "        # 模型评估\n",
    "        model.eval()\n",
    "        accuracy_accumulate = 0\n",
    "        sample_count = 0\n",
    "        for batch_count, batch in enumerate(test_dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            # 前向传播\n",
    "            with torch.no_grad():\n",
    "                output = model(input_ids, attention_mask, token_type_ids)\n",
    "            # 计算准确率\n",
    "            preds = torch.argmax(output, dim=-1)\n",
    "            mask = labels != -100\n",
    "            this_accuracy = (preds[mask] == labels[mask]).sum().item()\n",
    "            accuracy_accumulate += this_accuracy\n",
    "            sample_count += mask.sum().item()\n",
    "            print(f\"\\r评估：epoch:{epoch:0>2}[{'='*(int((batch_count+1) / len(test_dataloader) * 50)):<50}]\", end=\"\")\n",
    "            print(f\" accuracy={this_accuracy/mask.sum().item()}\", end=\"\")\n",
    "        print(f\"\\naccuracy: {accuracy_accumulate/sample_count}\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 5e-5\n",
    "num_epoch = 5\n",
    "train(model, train_dataloader, test_dataloader, lr, num_epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input):\n",
    "    pt_input = tokenizer(\n",
    "        input,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "    # 获取掩码位置\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    mask_positions = (pt_input[\"input_ids\"] == mask_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(**pt_input)\n",
    "    print(output.shape)\n",
    "    output = output.argmax(dim=1)\n",
    "    print(output)\n",
    "    # 获取输出中概率最大的词的索引\n",
    "    predicted_idx = output.argmax(dim=-1)\n",
    "    # 将索引转换为词\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_idx)\n",
    "    # 输出拼接后的句子\n",
    "    return [sentence.replace(\"[MASK]\", predicted_token) for sentence, predicted_token in zip(text, predicted_tokens)]\n",
    "\n",
    "\n",
    "model.to(\"cpu\")\n",
    "text = [\"立夏：春[MASK]落尽，夏木成荫\", \"一个人去爬[MASK]合适吗？\"]\n",
    "res = predict(model, text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, tokenizer, device=\"cpu\", top_k=5):\n",
    "    # 处理输入并定位掩码位置\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "\n",
    "    # 获取掩码位置\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    mask_positions = (inputs[\"input_ids\"] == mask_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "    # 模型预测\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device), inputs[\"token_type_ids\"].to(device)\n",
    "        )\n",
    "\n",
    "    # 处理预测结果\n",
    "    modified_input_ids = inputs[\"input_ids\"].clone()\n",
    "    for batch_idx, seq_idx in zip(*mask_positions):\n",
    "        # 获取对应位置的logits\n",
    "        logits = outputs[batch_idx, seq_idx]\n",
    "\n",
    "        # 取topk概率\n",
    "        topk = torch.topk(logits, top_k)\n",
    "        probabilities = torch.softmax(topk.values, dim=-1)\n",
    "\n",
    "        # 按概率随机选择\n",
    "        selected_idx = torch.multinomial(probabilities, 1)\n",
    "        selected_token_id = topk.indices[selected_idx]\n",
    "\n",
    "        # 替换掩码位置\n",
    "        modified_input_ids[batch_idx, seq_idx] = selected_token_id\n",
    "\n",
    "    # 解码生成文本\n",
    "    return tokenizer.batch_decode(modified_input_ids, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "model.to(\"cpu\")\n",
    "text = [\"立夏：春[MASK]落尽，夏木成荫\", \"一个人去爬[MASK]合适吗？\"]\n",
    "res = predict(model, text, tokenizer, device=\"cpu\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
