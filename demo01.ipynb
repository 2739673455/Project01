{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "import torch.nn as nn\n",
            "import jieba\n",
            "\n",
            "# 设置随机种子\n",
            "torch.manual_seed(42)\n",
            "text = \"自然语言是由文字构成的，而语言的含义是由单词构成的。即单词是含义的最小单位。因此为了让计算机理解自然语言，首先要让它理解单词含义。\"\n",
            "# 自定义停用词和标点符号\n",
            "stopwords = {\"的\", \"是\", \"而\", \"由\", \"，\", \"。\", \"、\"}\n",
            "# 分词，过滤停用词和标点，去重\n",
            "words = [word for word in jieba.lcut(text) if word not in stopwords]\n",
            "unique_words = list(set(words))\n",
            "# 构建词表\n",
            "word_to_idx = dict()  # 词到索引的映射\n",
            "idx_to_word = dict()  # 索引到词的映射\n",
            "for idx, word in enumerate(unique_words):\n",
            "    word_to_idx[word] = idx\n",
            "    idx_to_word[idx] = word\n",
            "# 初始化嵌入层\n",
            "embed = nn.Embedding(num_embeddings=len(word_to_idx), embedding_dim=5)\n",
            "\n",
            "\n",
            "rnn = torch.nn.RNN(input_size=4, hidden_size=2, num_layers=10)\n",
            "# input_size:输入数据的特征维度\n",
            "# hidden_size:隐藏层的单元数\n",
            "# num_layers:隐藏层的层数\n",
            "x = embed(torch.tensor([0, 1, 2])).unsqueeze(0)\n",
            "print(x)\n",
            "h0 = torch.randn(10, 4, 2)\n",
            "output, h1 = rnn(input=x, hx=h0)\n",
            "# print(output)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "pytorch-2.6.0-gpu",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.8"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
